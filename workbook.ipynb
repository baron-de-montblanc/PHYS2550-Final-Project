{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Cluster Redshift Classification Using Machine Learning\n",
    "\n",
    "Spring 2024 - PHYS 2550 - Final Project\n",
    "\n",
    "*Jade Ducharme, Zacharias Escalante, Fei Fan, Soren Helhoski, Shi Yan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to develop a machine learning model for classifying the redshifts of background\n",
    "galaxies behind galaxy clusters using observational cosmology. By leveraging photometric proper-\n",
    "ties of stars and galaxies, the project seeks to calculate new redshift values for each galaxy and\n",
    "compare these with known spectroscopic redshift values to evaluate the modelâ€™s accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"    # in case of library conflict, was unable to run program without this (Feifan)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for aesthetics/plotting\n",
    "sns.set_theme()\n",
    "plt.style.use(\"seaborn-v0_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from preprocess import load\n",
    "\n",
    "data, labels, features = load(\"./data/clean_specz_fluxes.csv\", mode=\"mag\")\n",
    "\n",
    "print(\"Data shape [input_size, num_features]:\\t\", data.shape)\n",
    "print(\"Label size [input_size,]:\\t\\t\", labels.shape,\"\\n\")\n",
    "print(\"Feature names:\", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our inputs. First, we can plot the 1D histogram for any of our input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input visualization\n",
    "from visualize import histogram_input\n",
    "\n",
    "histogram_input(data, features, plot_feature=\"i_cmodel_mag\", nbins=50, xrange=(12,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can also view how our labels align with any of the features in a 2D plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import plot_labels_features\n",
    "\n",
    "plot_labels_features(data, labels, features, plot_feature=\"z_cmodel_mag\", yrange=(0,1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess_split\n",
    "from model import Simple1DCNN, train1D, test1D, train_one_epoch, test\n",
    "\n",
    "# model initialization\n",
    "model = Simple1DCNN(num_features=len(features), num_classes=1)\n",
    "\n",
    "# Define the loss function and optimizer with weight decay\n",
    "weight_decay = 1e-6  # Adjust this value as needed\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=weight_decay)  # Adding weight decay to Adam optimizer\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.000001)\n",
    "acc_metric = torchmetrics.R2Score()\n",
    "\n",
    "\n",
    "# Determine the device (CPU or GPU) for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# The device is determined based on the availability of CUDA (GPU support) using torch.device.\n",
    "\n",
    "# Data preparation\n",
    "train_set, val_set, test_set = preprocess_split(data, labels, train_split=0.7, val_split=0.15)\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 20\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "\n",
    "loss_list, acc_list = [], []\n",
    "val_loss_list, val_acc_list = [], []\n",
    "\n",
    "\n",
    "for e in range(1,num_epochs+1):\n",
    "\n",
    "    # training\n",
    "    loss, acc = train1D(model, device, train_loader, optimizer, criterion, acc_metric)\n",
    "    loss_list.append(loss)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "    # validation\n",
    "    val_loss, val_acc = test1D(model, device, test_loader, criterion, acc_metric)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {e}: Train Loss: {loss:.4f}, Train Acc: {acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on unseen data?\n",
    "\n",
    "model = Simple1DCNN(num_features=len(features), num_classes=1)  \n",
    "model.eval()\n",
    "test_loss, test_acc = test1D(model, device, test_loader, criterion, acc_metric)\n",
    "print(f\"Final test loss: {test_loss:.4f}\\t Final test acc: {test_acc:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import plot_loss, plot_accuracy\n",
    "\n",
    "plot_loss(loss_list, val_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about data\n",
    "\n",
    "data, labels, features = load(\"./data/clean_specz_fluxes.csv\", mode=\"mag\") #Load in data\n",
    "\n",
    "# print(\"Data shape [input_size, num_features]:\\t\", data.shape) #Get data attributes\n",
    "# print(\"Label size [input_size,]:\\t\\t\", labels.shape,\"\\n\")\n",
    "# print(\"Feature names:\", features)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from visualize import visualize_knn_predictions\n",
    "\n",
    "minmax_scaler = MinMaxScaler() #Method of scaling feature values\n",
    "standard_scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "    # test_mse.append(mean_squared_error(test_labels, y_pred))\n",
    "\n",
    "data_rescaled_minmax = minmax_scaler.fit_transform(data) #Scale feature data to lie in (0,1)\n",
    "data_rescaled_standard = standard_scaler.fit_transform(data)\n",
    "data_rescaled_robust = robust_scaler.fit_transform(data)\n",
    "\n",
    "X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax = train_test_split(data_rescaled_minmax, labels, test_size=0.2) #Shuffle and split data in training (20%) and testing (80%)\n",
    "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(data_rescaled_standard, labels, test_size=0.2) #Shuffle and split data in training (20%) and testing (80%)\n",
    "X_train_robust, X_test_robust, y_train_robust, y_test_robust = train_test_split(data_rescaled_robust, labels, test_size=0.2) #Shuffle and split data in training (20%) and testing (80%)\n",
    "\n",
    "k_vals = range(1, 400, 5) #Range of k neighbors to try\n",
    "\n",
    "# Training\n",
    "\n",
    "def knn_regression(train_data, test_data, train_labels, test_labels, k):\n",
    "    knn = KNeighborsRegressor(n_neighbors = val, weights = \"distance\") #Default weights are \"uniform\". \"distance\" weight points by the inverse of their distance.\n",
    "    knn.fit(train_data, train_labels)\n",
    "\n",
    "    y_pred = knn.predict(test_data)\n",
    "\n",
    "    return mean_squared_error(test_labels, y_pred) #Returns mse\n",
    "\n",
    "test_mse_minmax = []; test_mse_standard = []; test_mse_robust = [];\n",
    "\n",
    "\n",
    "for val in k_vals:\n",
    "    test_mse_minmax.append(knn_regression(X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax, k = val))\n",
    "    test_mse_standard.append(knn_regression(X_train_standard, X_test_standard, y_train_standard, y_test_standard, k = val))\n",
    "    test_mse_robust.append(knn_regression(X_train_robust, X_test_robust, y_train_robust, y_test_robust, k = val))\n",
    "\n",
    "k_opt_minmax = k_vals[test_mse_minmax.index(min(test_mse_minmax))] \n",
    "k_opt_standard = k_vals[test_mse_standard.index(min(test_mse_standard))] \n",
    "k_opt_robust = k_vals[test_mse_robust.index(min(test_mse_robust))] \n",
    "\n",
    "print(f'Test mse minmax: {test_mse_minmax[test_mse_minmax.index(min(test_mse_minmax))]}')\n",
    "print(f'Optimal k minmax: {k_opt_minmax}')\n",
    "\n",
    "print(f'Test mse standard: {test_mse_standard[test_mse_standard.index(min(test_mse_standard))]}')\n",
    "print(f'Optimal k standard: {k_opt_standard}')\n",
    "\n",
    "print(f'Test mse robust: {test_mse_robust[test_mse_robust.index(min(test_mse_robust))]}')\n",
    "print(f'Optimal k robust: {k_opt_robust}')\n",
    "\n",
    "# KNN Visualization\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.title(\"KNN Mean Squared Error\", y=1.02)\n",
    "plt.semilogx(k_vals, test_mse_minmax, linestyle=\"\", marker=\".\", markersize=4, label=\"Test MSE MinMax\")\n",
    "plt.semilogx(k_vals, test_mse_standard, linestyle=\"\", marker=\"*\", markersize=4, label=\"Test MSE Standard\")\n",
    "plt.semilogx(k_vals, test_mse_robust, linestyle=\"\", marker=\"v\", markersize=4, label=\"Test MSE Robust\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "# plt.xlim(xrange[0], xrange[1])\n",
    "# plt.ylim(yrange[0], yrange[1])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "knn_opt_minmax = KNeighborsRegressor(n_neighbors = k_opt_minmax, weights = \"distance\")\n",
    "knn_opt_minmax.fit(X_train_minmax, y_train_minmax)\n",
    "y_opt_pred_minmax = knn_opt_minmax.predict(X_test_minmax)\n",
    "\n",
    "knn_opt_standard = KNeighborsRegressor(n_neighbors = k_opt_standard, weights = \"distance\")\n",
    "knn_opt_standard.fit(X_train_standard, y_train_standard)\n",
    "y_opt_pred_standard = knn_opt_standard.predict(X_test_standard)\n",
    "\n",
    "knn_opt_robust = KNeighborsRegressor(n_neighbors = k_opt_robust, weights = \"distance\")\n",
    "knn_opt_robust.fit(X_train_robust, y_train_robust)\n",
    "y_opt_pred_robust = knn_opt_robust.predict(X_test_robust)\n",
    "\n",
    "print(f'test mse mimax: {mean_squared_error(y_test_minmax, y_opt_pred_minmax)}')\n",
    "visualize_knn_predictions(y_test_minmax, y_opt_pred_minmax, device = device, xrange=(0,1.5), yrange=(0,1.5))\n",
    "print(f'test mse standard: {mean_squared_error(y_test_standard, y_opt_pred_standard)}')\n",
    "visualize_knn_predictions(y_test_standard, y_opt_pred_standard, device = device, xrange=(0,1.5), yrange=(0,1.5))\n",
    "print(f'test mse robust: {mean_squared_error(y_test_robust, y_opt_pred_robust)}')\n",
    "visualize_knn_predictions(y_test_robust, y_opt_pred_robust, device = device, xrange=(0,1.5), yrange=(0,1.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
